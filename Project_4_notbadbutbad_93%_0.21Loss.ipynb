{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb60cf55",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b62792bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfd310",
   "metadata": {},
   "source": [
    "## Selected Data & their (sub)directories\n",
    "15 species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4876775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list of chosen birds\n",
    "\n",
    "birds = 'FLAMINGO, OKINAWA RAIL, NORTHERN PARULA, OVENBIRD, SUPERB STARLING, WALL CREAPER, RED NAPED TROGON, NORTHERN JACANA, MAGPIE GOOSE, IVORY GULL, KOOKABURRA, KILLDEAR, PARADISE TANAGER, RED BELLIED PITTA, RUDY KINGFISHER, STRAWBERRY FINCH'\n",
    "birds = birds.split(', ')\n",
    "birds = sorted(birds)\n",
    "\n",
    "# birds = ['IVORY GULL', 'KILLDEAR', 'KOOKABURRA', ...]\n",
    "# len(birds) = 15\n",
    "len(birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ce1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of directories of all of the birds\n",
    "\n",
    "DIR = 'train'\n",
    "subnames = [name for name in os.listdir(DIR) if os.path.isdir(os.path.join(DIR, name))]\n",
    "\n",
    "# subanames = [ABBOTTS BABBLER, ABBOTS BOOBY, ...]\n",
    "# len(subnames) = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7e51d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of our chosen species' subdirectories\n",
    "\n",
    "trainDIR = 'train/'\n",
    "trainsubs = [trainDIR+str(bird)+'/' for bird in birds]\n",
    "\n",
    "testDIR = 'test/'\n",
    "testsubs = [testDIR+str(bird)+'/' for bird in birds]\n",
    "\n",
    "validDIR = 'valid/'\n",
    "validsubs = [validDIR+str(bird)+'/' for bird in birds]\n",
    "\n",
    "\n",
    "# trainsubs = ['train/OKINAWA RAIL/',\n",
    "#                       ...\n",
    "#            'train/STRAWBERRY FINCH/']\n",
    "\n",
    "# testsubs = ['test/OKINAWA RAIL/',\n",
    "#                       ...\n",
    "#            'test/STRAWBERRY FINCH/']\n",
    "\n",
    "# validsubs = ['valid/OKINAWA RAIL/',\n",
    "#                       ...\n",
    "#            'valid/STRAWBERRY FINCH/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05af1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of indices for our 15 selected birds, sorted.\n",
    "\n",
    "indices = []\n",
    "for i in range(len(subnames)):\n",
    "    if subnames[i] in birds:\n",
    "        indices.append(i)\n",
    "        \n",
    "# indices = [236, 245, 248, ...]\n",
    "# len(indices) = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d073e",
   "metadata": {},
   "source": [
    "## Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8640f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel size\n",
    "pixels = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f31af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5760, 5760)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the list of arrays for our train data. They get normalized.\n",
    "\n",
    "trainimglist = []\n",
    "trainindlist = []\n",
    "for i in range(len(trainsubs)):\n",
    "    jpgs = next(os.walk(trainsubs[i]))[2][:120] #list of files in the subdir\n",
    "    for jpg in jpgs:\n",
    "        img_array = cv2.imread(os.path.join(trainsubs[i],jpg), cv2.IMREAD_COLOR)\n",
    "        new_array = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        trainimglist.append(new_array)\n",
    "        trainindlist.append(i)\n",
    "        \n",
    "        img_array = cv2.imread(os.path.join(trainsubs[i],jpg))\n",
    "        \n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "        new_gray = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        trainimglist.append(new_gray)\n",
    "        trainindlist.append(i)\n",
    "        \n",
    "        flip = cv2.flip(img_array, 0)\n",
    "        new_flip = cv2.resize(flip, (pixels, pixels))/255.\n",
    "        trainimglist.append(new_flip)\n",
    "        trainindlist.append(i)\n",
    "        \n",
    "# len(trainimglist) = 5400            # The list of img arrays\n",
    "# len(trainindlist) = 5400            # The list of indices associated with each array of same index in trainimglist\n",
    "len(trainimglist), len(trainindlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9be225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list of arrays for our test data. They get normalized, too.\n",
    "\n",
    "testimglist = []\n",
    "testindlist = []\n",
    "for i in range(len(testsubs)):\n",
    "    jpgs = next(os.walk(testsubs[i]))[2] #list of files in the subdir\n",
    "    for jpg in jpgs:\n",
    "        img_array = cv2.imread(os.path.join(testsubs[i],jpg), cv2.IMREAD_COLOR)\n",
    "        new_array = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        testimglist.append(new_array)\n",
    "        testindlist.append(i)\n",
    "# len(testimglist) = 75            # The list of img arrays\n",
    "# len(testindlist) = 75            # The list of indices associated with each array of same index in imglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7946695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list of arrays for our validation data. They get normalized, too.\n",
    "\n",
    "validimglist = []\n",
    "validindlist = []\n",
    "for i in range(len(validsubs)):\n",
    "    jpgs = next(os.walk(validsubs[i]))[2] #list of files in the subdir\n",
    "    for jpg in jpgs:\n",
    "        img_array = cv2.imread(os.path.join(validsubs[i],jpg), cv2.IMREAD_COLOR)\n",
    "        new_array = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        validimglist.append(new_array)\n",
    "        validindlist.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e1d46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5760, 100, 100, 3),\n",
       " (5760,),\n",
       " (80, 100, 100, 3),\n",
       " (80,),\n",
       " (80, 100, 100, 3),\n",
       " (80,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing our train/test data to numpy arrays\n",
    "\n",
    "X_train = np.array(trainimglist)\n",
    "y_train = np.array(trainindlist)\n",
    "X_test = np.array(testimglist)\n",
    "y_test = np.array(testindlist)\n",
    "X_valid = np.array(testimglist)\n",
    "y_valid = np.array(testindlist)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_valid.shape, y_valid.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96499c21",
   "metadata": {},
   "source": [
    "## Current best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0524d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5760, 100, 100, 3, 1)\n",
      "5760 train samples\n",
      "80 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 49, 49, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 10, 10, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               524416    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 914,896\n",
      "Trainable params: 914,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Current best model -- Use the next cells below to make changes and print new results while keeping these ones. Update \n",
    "# Delete these when we get a better one if desired.\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "X_train = np.array(trainimglist)\n",
    "y_train = np.array(trainindlist)\n",
    "X_test = np.array(testimglist)\n",
    "y_test = np.array(testindlist)\n",
    "X_valid = np.array(testimglist)\n",
    "y_valid = np.array(testindlist)\n",
    "\n",
    "\n",
    "num_classes = 16\n",
    "input_shape = (pixels,pixels,3)\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "X_valid = np.expand_dims(X_valid, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "# 4 x [ Conv2D + MaxPooling2D ] layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8d87688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "52/52 [==============================] - 26s 490ms/step - loss: 2.1669 - accuracy: 0.2799 - val_loss: 9.5306 - val_accuracy: 0.0243\n",
      "Epoch 2/10\n",
      "52/52 [==============================] - 26s 494ms/step - loss: 1.3761 - accuracy: 0.5527 - val_loss: 8.6452 - val_accuracy: 0.1094\n",
      "Epoch 3/10\n",
      "52/52 [==============================] - 27s 516ms/step - loss: 0.9464 - accuracy: 0.7051 - val_loss: 8.1146 - val_accuracy: 0.2830\n",
      "Epoch 4/10\n",
      "52/52 [==============================] - 27s 523ms/step - loss: 0.6722 - accuracy: 0.7803 - val_loss: 9.5775 - val_accuracy: 0.1302\n",
      "Epoch 5/10\n",
      "52/52 [==============================] - 29s 550ms/step - loss: 0.5356 - accuracy: 0.8308 - val_loss: 8.5895 - val_accuracy: 0.3142\n",
      "Epoch 6/10\n",
      "52/52 [==============================] - 29s 555ms/step - loss: 0.3983 - accuracy: 0.8715 - val_loss: 10.5301 - val_accuracy: 0.2726\n",
      "Epoch 7/10\n",
      "52/52 [==============================] - 28s 543ms/step - loss: 0.3149 - accuracy: 0.8951 - val_loss: 10.0520 - val_accuracy: 0.3108\n",
      "Epoch 8/10\n",
      "52/52 [==============================] - 27s 513ms/step - loss: 0.2583 - accuracy: 0.9153 - val_loss: 10.5814 - val_accuracy: 0.3090\n",
      "Epoch 9/10\n",
      "52/52 [==============================] - 26s 494ms/step - loss: 0.2116 - accuracy: 0.9309 - val_loss: 11.0341 - val_accuracy: 0.3316\n",
      "Epoch 10/10\n",
      "52/52 [==============================] - 27s 520ms/step - loss: 0.1831 - accuracy: 0.9427 - val_loss: 9.7324 - val_accuracy: 0.3351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a128d09700>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "val_split = 0.1\n",
    "early_stopping = [\n",
    "    EarlyStopping(monitor='val_loss', patience=4), \n",
    "    EarlyStopping(monitor='accuracy', patience=4, min_delta=.02)\n",
    "]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=val_split, callbacks=None)\n",
    "#Change val_split for more traindata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('flamingo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model23 = tf.keras.models.load_model('flamingo')\n",
    "score_v = model23.evaluate(X_valid, y_valid)\n",
    "print(score_v[0])\n",
    "print(score_v[1])\n",
    "score_v2 = model23.evaluate(X_test, y_test)\n",
    "print(score_v2[0])\n",
    "print(score_v2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebb510",
   "metadata": {},
   "source": [
    "## Model with a chip on its shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ac020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Have to reinitialize our train/test vars because running the model modifies it\n",
    "# X_train = np.array(trainimglist)\n",
    "# y_train = np.array(trainindlist)\n",
    "# X_test = np.array(testimglist)\n",
    "# y_test = np.array(testindlist)\n",
    "\n",
    "\n",
    "# num_classes = 15\n",
    "# input_shape = (80,80,3)\n",
    "\n",
    "# X_train = np.expand_dims(X_train, -1)\n",
    "# X_test = np.expand_dims(X_test, -1)\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(X_train.shape[0], \"train samples\")\n",
    "# print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# # Use different layers here!!!\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.Input(shape=input_shape),\n",
    "#         layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#         layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\"),\n",
    "#         layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "#         layers.Flatten(),\n",
    "#         layers.Dropout(0.5),\n",
    "#         layers.Dense(num_classes, activation=\"softmax\"),\n",
    "#     ] layers.\n",
    "# )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a573c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
