{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb60cf55",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62792bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfd310",
   "metadata": {},
   "source": [
    "## Selected Data & their (sub)directories\n",
    "15 species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4876775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list of chosen birds\n",
    "\n",
    "birds = 'OKINAWA RAIL, NORTHERN PARULA, OVENBIRD, SUPERB STARLING, WALL CREAPER, RED NAPED TROGON, NORTHERN JACANA, MAGPIE GOOSE, IVORY GULL, KOOKABURRA, KILLDEAR, PARADISE TANAGER, RED BELLIED PITTA, RUDY KINGFISHER, STRAWBERRY FINCH'\n",
    "birds = birds.split(', ')\n",
    "birds = sorted(birds)\n",
    "\n",
    "# birds = ['IVORY GULL', 'KILLDEAR', 'KOOKABURRA', ...]\n",
    "# len(birds) = 15\n",
    "len(birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5ce1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of directories of all of the \n",
    "birds\n",
    "\n",
    "DIR = 'train'\n",
    "subnames = [name for name in os.listdir(DIR) if os.path.isdir(os.path.join(DIR, name))]\n",
    "\n",
    "# subanames = [ABBOTTS BABBLER, ABBOTS BOOBY, ...]\n",
    "# len(subnames) = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7e51d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of our chosen species' subdirectories\n",
    "\n",
    "trainDIR = 'train/'\n",
    "trainsubs = [trainDIR+str(bird)+'/' for bird in birds]\n",
    "\n",
    "testDIR = 'test/'\n",
    "testsubs = [testDIR+str(bird)+'/' for bird in birds]\n",
    "\n",
    "validDIR = 'valid/'\n",
    "validsubs = [validDIR+str(bird)+'/' for bird in birds]\n",
    "\n",
    "\n",
    "# trainsubs = ['train/OKINAWA RAIL/',\n",
    "#                       ...\n",
    "#            'train/STRAWBERRY FINCH/']\n",
    "\n",
    "# testsubs = ['test/OKINAWA RAIL/',\n",
    "#                       ...\n",
    "#            'test/STRAWBERRY FINCH/']\n",
    "\n",
    "# validsubs = ['valid/OKINAWA RAIL/',\n",
    "#                       ...\n",
    "#            'valid/STRAWBERRY FINCH/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05af1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of indices for our 15 selected birds, sorted.\n",
    "\n",
    "indices = []\n",
    "for i in range(len(subnames)):\n",
    "    if subnames[i] in birds:\n",
    "        indices.append(i)\n",
    "        \n",
    "# indices = [236, 245, 248, ...]\n",
    "# len(indices) = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d073e",
   "metadata": {},
   "source": [
    "## Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8640f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel size\n",
    "pixels = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02f31af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5400, 5400)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the list of arrays for our train data. They get normalized.\n",
    "\n",
    "trainimglist = []\n",
    "trainindlist = []\n",
    "for i in range(len(trainsubs)):\n",
    "    jpgs = next(os.walk(trainsubs[i]))[2][:120] #list of files in the subdir\n",
    "    for jpg in jpgs:\n",
    "        img_array = cv2.imread(os.path.join(trainsubs[i],jpg), cv2.IMREAD_COLOR)\n",
    "        new_array = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        trainimglist.append(new_array)\n",
    "        trainindlist.append(i)\n",
    "        \n",
    "        img_array = cv2.imread(os.path.join(trainsubs[i],jpg))\n",
    "        \n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "        new_gray = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        trainimglist.append(new_gray)\n",
    "        trainindlist.append(i)\n",
    "        \n",
    "        flip = cv2.flip(img_array, 0)\n",
    "        new_flip = cv2.resize(flip, (pixels, pixels))/255.\n",
    "        trainimglist.append(new_flip)\n",
    "        trainindlist.append(i)\n",
    "        \n",
    "# len(trainimglist) = 5400            # The list of img arrays\n",
    "# len(trainindlist) = 5400            # The list of indices associated with each array of same index in trainimglist\n",
    "len(trainimglist), len(trainindlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d9be225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list of arrays for our test data. They get normalized, too.\n",
    "\n",
    "testimglist = []\n",
    "testindlist = []\n",
    "for i in range(len(testsubs)):\n",
    "    jpgs = next(os.walk(testsubs[i]))[2] #list of files in the subdir\n",
    "    for jpg in jpgs:\n",
    "        img_array = cv2.imread(os.path.join(testsubs[i],jpg), cv2.IMREAD_COLOR)\n",
    "        new_array = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        testimglist.append(new_array)\n",
    "        testindlist.append(i)\n",
    "# len(testimglist) = 75            # The list of img arrays\n",
    "# len(testindlist) = 75            # The list of indices associated with each array of same index in imglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7946695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the list of arrays for our validation data. They get normalized, too.\n",
    "\n",
    "validimglist = []\n",
    "validindlist = []\n",
    "for i in range(len(validsubs)):\n",
    "    jpgs = next(os.walk(validsubs[i]))[2] #list of files in the subdir\n",
    "    for jpg in jpgs:\n",
    "        img_array = cv2.imread(os.path.join(validsubs[i],jpg), cv2.IMREAD_COLOR)\n",
    "        new_array = cv2.resize(img_array, (pixels, pixels))/255.\n",
    "        validimglist.append(new_array)\n",
    "        validindlist.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15e1d46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5400, 100, 100, 3),\n",
       " (5400,),\n",
       " (75, 100, 100, 3),\n",
       " (75,),\n",
       " (75, 100, 100, 3),\n",
       " (75,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing our train/test data to numpy arrays\n",
    "\n",
    "X_train = np.array(trainimglist)\n",
    "y_train = np.array(trainindlist)\n",
    "X_test = np.array(testimglist)\n",
    "y_test = np.array(testindlist)\n",
    "X_valid = np.array(testimglist)\n",
    "y_valid = np.array(testindlist)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_valid.shape, y_valid.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96499c21",
   "metadata": {},
   "source": [
    "## Current best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0524d1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5400, 100, 100, 3, 1)\n",
      "5400 train samples\n",
      "75 test samples\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 49, 49, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 23, 23, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 10, 10, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 15)                61455     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 449,871\n",
      "Trainable params: 449,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Current best model -- Use the next cells below to make changes and print new results while keeping these ones. Update \n",
    "# Delete these when we get a better one if desired.\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "X_train = np.array(trainimglist)\n",
    "y_train = np.array(trainindlist)\n",
    "X_test = np.array(testimglist)\n",
    "y_test = np.array(testindlist)\n",
    "X_valid = np.array(testimglist)\n",
    "y_valid = np.array(testindlist)\n",
    "\n",
    "\n",
    "num_classes = 15\n",
    "input_shape = (pixels,pixels,3)\n",
    "\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "X_valid = np.expand_dims(X_valid, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_test, num_classes)\n",
    "X_valid = np.expand_dims(X_valid, -1)\n",
    "\n",
    "# 4 x [ Conv2D + MaxPooling2D ] layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8d87688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "52/52 [==============================] - 40s 712ms/step - loss: 2.0905 - accuracy: 0.2729 - val_loss: 2.9886 - val_accuracy: 0.0074\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 41s 791ms/step - loss: 1.3325 - accuracy: 0.5511 - val_loss: 2.2456 - val_accuracy: 0.2000\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 40s 771ms/step - loss: 0.9960 - accuracy: 0.6657 - val_loss: 2.3448 - val_accuracy: 0.2185\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 41s 793ms/step - loss: 0.7586 - accuracy: 0.7478 - val_loss: 1.8219 - val_accuracy: 0.3778\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - 40s 765ms/step - loss: 0.6176 - accuracy: 0.7988 - val_loss: 2.0765 - val_accuracy: 0.3111\n",
      "Epoch 6/15\n",
      "52/52 [==============================] - 45s 858ms/step - loss: 0.4574 - accuracy: 0.8532 - val_loss: 1.1341 - val_accuracy: 0.6519\n",
      "Epoch 7/15\n",
      "52/52 [==============================] - 46s 892ms/step - loss: 0.3905 - accuracy: 0.8768 - val_loss: 1.1774 - val_accuracy: 0.6074\n",
      "Epoch 8/15\n",
      "52/52 [==============================] - 40s 771ms/step - loss: 0.3356 - accuracy: 0.8949 - val_loss: 1.4148 - val_accuracy: 0.5333\n",
      "Epoch 9/15\n",
      "52/52 [==============================] - 38s 738ms/step - loss: 0.2843 - accuracy: 0.9099 - val_loss: 1.1983 - val_accuracy: 0.7222\n",
      "Epoch 10/15\n",
      "52/52 [==============================] - 38s 740ms/step - loss: 0.2194 - accuracy: 0.9283 - val_loss: 1.7153 - val_accuracy: 0.5963\n",
      "Epoch 11/15\n",
      "52/52 [==============================] - 38s 736ms/step - loss: 0.1991 - accuracy: 0.9370 - val_loss: 1.5324 - val_accuracy: 0.6296\n",
      "Epoch 12/15\n",
      "52/52 [==============================] - 39s 743ms/step - loss: 0.1826 - accuracy: 0.9423 - val_loss: 1.5262 - val_accuracy: 0.6556\n",
      "Epoch 13/15\n",
      "52/52 [==============================] - 40s 778ms/step - loss: 0.1440 - accuracy: 0.9552 - val_loss: 1.3731 - val_accuracy: 0.6852\n",
      "Epoch 14/15\n",
      "52/52 [==============================] - 41s 781ms/step - loss: 0.1033 - accuracy: 0.9663 - val_loss: 0.8477 - val_accuracy: 0.8222\n",
      "Epoch 15/15\n",
      "52/52 [==============================] - 44s 852ms/step - loss: 0.0957 - accuracy: 0.9700 - val_loss: 1.3315 - val_accuracy: 0.7111\n",
      "Test loss: 0.5504311919212341\n",
      "Test accuracy: 0.8799999952316284\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 15\n",
    "val_split = 0.05\n",
    "early_stopping = [\n",
    "    EarlyStopping(monitor='val_loss', patience=4), \n",
    "    EarlyStopping(monitor='accuracy', patience=4, min_delta=.02)\n",
    "]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=val_split, callbacks=None)\n",
    "#Change val_split for more traindata\n",
    "\n",
    "###############################\n",
    "\n",
    "#  -> isntead of xtest, ytest, try X_valid, y_valid\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "933c8cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ourbestmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ourbestmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c81e2459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2ac69f9de80>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('ourbestmodel')\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d46ac020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75, 100, 100, 3, 1), (75, 15, 15))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = np.array(testimglist)\n",
    "y_valid = np.array(testindlist)\n",
    "\n",
    "y_valid = keras.utils.to_categorical(y_test, num_classes)\n",
    "X_valid = np.expand_dims(X_valid, -1)\n",
    "\n",
    "X_valid.shape, y_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a573c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1473, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 15, 15) and (None, 15) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14240/2057144067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## Here for some reason we did not succeed in laoding this model, but on the other uploaded file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m## (named 'Project_4_add-on'), we successfully validated an older but less performant one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1525, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1507, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1473, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\sampr\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 15, 15) and (None, 15) are incompatible\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate(X_valid, y_valid)\n",
    "score\n",
    "\n",
    "## Here for some reason we did not succeed in laoding this model, but on the other uploaded file \n",
    "## (named 'Project_4_add-on'), we successfully validated on an older but less performant one.\n",
    "\n",
    "###### At the end of the 'add-on' notebook, you should be able to see this:\n",
    "## from tensorflow import keras\n",
    "## model1 = keras.models.load_model('bestmodel')\n",
    "## score = model1.evaluate(X_valid, y_valid, verbose = 0)\n",
    "## score\n",
    "##\n",
    "\n",
    "## [0.4565109312534332, 0.9200000166893005]\n",
    "##      LOSS              ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809afd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
